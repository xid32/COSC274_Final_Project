{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load and Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "      <th>style</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>11 12, 2016</td>\n",
       "      <td>C413C78E10E54C5DB41837889F36C1E8</td>\n",
       "      <td>565D194F38B1CC3F806EE677C61F639C</td>\n",
       "      <td>465E154EC79AFFAB5EB2607198B21433</td>\n",
       "      <td>all of the reviews for this product are fake.</td>\n",
       "      <td>All fake reviews, beware.</td>\n",
       "      <td>1478908800</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Size:': ' Polaris H4'}</td>\n",
       "      <td>automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12 6, 2016</td>\n",
       "      <td>490AE37808EFEE3AF4FE6DEBDEB5A4C8</td>\n",
       "      <td>0D66512A0A7F580523AB996378DF0F14</td>\n",
       "      <td>760C63E8E5E8DC3FAA01878D37BA5678</td>\n",
       "      <td>wrong part. our fault.</td>\n",
       "      <td>One Star</td>\n",
       "      <td>1480982400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>09 17, 2014</td>\n",
       "      <td>74A9FA5A64449BEE2A2E8E3F62872F0F</td>\n",
       "      <td>A0E45600FF2C5A779CB4314F379C253A</td>\n",
       "      <td>C6E4DD5C1C4EC09E90182644ED6CA9EF</td>\n",
       "      <td>this wire set it really sucks!!!</td>\n",
       "      <td>One Star</td>\n",
       "      <td>1410912000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>06 11, 2016</td>\n",
       "      <td>EB561158A2829D98B467FE03CC1E45F1</td>\n",
       "      <td>37AB9A82470595E0ACB88BAC48C150EE</td>\n",
       "      <td>F4892A77EA45C52F40AB17ED537EF9FF</td>\n",
       "      <td>first use, it leaked instantly. even at 5 buck...</td>\n",
       "      <td>One Star</td>\n",
       "      <td>1465603200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Color:': ' Clear', 'Style:': ' 45 Degree'}</td>\n",
       "      <td>automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12 23, 2017</td>\n",
       "      <td>5045D801332850D21618DD13A697CD9B</td>\n",
       "      <td>5772FF30428EEB8E0258C1A53CA2EC50</td>\n",
       "      <td>522F0BBFF2B47F1D63FF781A0AB1D079</td>\n",
       "      <td>didn't fit</td>\n",
       "      <td>One Star</td>\n",
       "      <td>1513987200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29184</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>03 20, 2015</td>\n",
       "      <td>24A0B29940152C574DA401347CE47E7A</td>\n",
       "      <td>CD83ED06223FE876323282B57209D765</td>\n",
       "      <td>1B5F1A160CB115EB26D0651E5BF59BE9</td>\n",
       "      <td>this is the same plush toy that the official d...</td>\n",
       "      <td>Well constructed, very soft</td>\n",
       "      <td>1426809600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>toys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29185</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>05 15, 2014</td>\n",
       "      <td>AD3FD1D6499FA73ACBCBB39F89EE5BF9</td>\n",
       "      <td>3625ADD67F860057FD15B71FD0389264</td>\n",
       "      <td>C8DC85A8F6B8527735AF7FA6182BB209</td>\n",
       "      <td>my grandson loved this. it is a great toy, he ...</td>\n",
       "      <td>Fun toy</td>\n",
       "      <td>1400112000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>toys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29186</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>11 13, 2017</td>\n",
       "      <td>24C8C33C6FD8ACCAFE2EC1D1FC4DBF05</td>\n",
       "      <td>0C0DF58B2AC0350731C4146D32DBD3F0</td>\n",
       "      <td>951CEFD3CA5CB6773251E773379FF26A</td>\n",
       "      <td>my kiddo loves them! we are a rock climbing fa...</td>\n",
       "      <td>and now the play set has a nice climbing feature</td>\n",
       "      <td>1510531200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>toys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29187</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>01 2, 2018</td>\n",
       "      <td>E313EE1C17E5E553343F50BBC95BB2C2</td>\n",
       "      <td>9C9D7AAF41631F1096FE10FBA18B6029</td>\n",
       "      <td>F5A4D2A1C2A0CAD7BBC378CB10CB410C</td>\n",
       "      <td>i bought this for my niece (age 2) and mailed ...</td>\n",
       "      <td>my brother said she liked it and I haven't see...</td>\n",
       "      <td>1514851200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Style:': ' Standard Version'}</td>\n",
       "      <td>toys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29188</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>07 30, 2016</td>\n",
       "      <td>BE12BFE2E36DE2B8892B31F0BE5F997F</td>\n",
       "      <td>7A052AB86002325D7201F33FB04EB113</td>\n",
       "      <td>1DB58EA9AE6AA8E377E34CBB502A3D69</td>\n",
       "      <td>my daughter will love this! she's a huge ninja...</td>\n",
       "      <td>Ninja fan will love!</td>\n",
       "      <td>1469836800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>toys</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29189 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       overall  verified   reviewTime                        reviewerID  \\\n",
       "0            1     False  11 12, 2016  C413C78E10E54C5DB41837889F36C1E8   \n",
       "1            1      True   12 6, 2016  490AE37808EFEE3AF4FE6DEBDEB5A4C8   \n",
       "2            1      True  09 17, 2014  74A9FA5A64449BEE2A2E8E3F62872F0F   \n",
       "3            1      True  06 11, 2016  EB561158A2829D98B467FE03CC1E45F1   \n",
       "4            1      True  12 23, 2017  5045D801332850D21618DD13A697CD9B   \n",
       "...        ...       ...          ...                               ...   \n",
       "29184        5      True  03 20, 2015  24A0B29940152C574DA401347CE47E7A   \n",
       "29185        5      True  05 15, 2014  AD3FD1D6499FA73ACBCBB39F89EE5BF9   \n",
       "29186        5      True  11 13, 2017  24C8C33C6FD8ACCAFE2EC1D1FC4DBF05   \n",
       "29187        5      True   01 2, 2018  E313EE1C17E5E553343F50BBC95BB2C2   \n",
       "29188        5      True  07 30, 2016  BE12BFE2E36DE2B8892B31F0BE5F997F   \n",
       "\n",
       "                                   asin                      reviewerName  \\\n",
       "0      565D194F38B1CC3F806EE677C61F639C  465E154EC79AFFAB5EB2607198B21433   \n",
       "1      0D66512A0A7F580523AB996378DF0F14  760C63E8E5E8DC3FAA01878D37BA5678   \n",
       "2      A0E45600FF2C5A779CB4314F379C253A  C6E4DD5C1C4EC09E90182644ED6CA9EF   \n",
       "3      37AB9A82470595E0ACB88BAC48C150EE  F4892A77EA45C52F40AB17ED537EF9FF   \n",
       "4      5772FF30428EEB8E0258C1A53CA2EC50  522F0BBFF2B47F1D63FF781A0AB1D079   \n",
       "...                                 ...                               ...   \n",
       "29184  CD83ED06223FE876323282B57209D765  1B5F1A160CB115EB26D0651E5BF59BE9   \n",
       "29185  3625ADD67F860057FD15B71FD0389264  C8DC85A8F6B8527735AF7FA6182BB209   \n",
       "29186  0C0DF58B2AC0350731C4146D32DBD3F0  951CEFD3CA5CB6773251E773379FF26A   \n",
       "29187  9C9D7AAF41631F1096FE10FBA18B6029  F5A4D2A1C2A0CAD7BBC378CB10CB410C   \n",
       "29188  7A052AB86002325D7201F33FB04EB113  1DB58EA9AE6AA8E377E34CBB502A3D69   \n",
       "\n",
       "                                              reviewText  \\\n",
       "0          all of the reviews for this product are fake.   \n",
       "1                                 wrong part. our fault.   \n",
       "2                       this wire set it really sucks!!!   \n",
       "3      first use, it leaked instantly. even at 5 buck...   \n",
       "4                                             didn't fit   \n",
       "...                                                  ...   \n",
       "29184  this is the same plush toy that the official d...   \n",
       "29185  my grandson loved this. it is a great toy, he ...   \n",
       "29186  my kiddo loves them! we are a rock climbing fa...   \n",
       "29187  i bought this for my niece (age 2) and mailed ...   \n",
       "29188  my daughter will love this! she's a huge ninja...   \n",
       "\n",
       "                                                 summary  unixReviewTime  \\\n",
       "0                              All fake reviews, beware.      1478908800   \n",
       "1                                               One Star      1480982400   \n",
       "2                                               One Star      1410912000   \n",
       "3                                               One Star      1465603200   \n",
       "4                                               One Star      1513987200   \n",
       "...                                                  ...             ...   \n",
       "29184                        Well constructed, very soft      1426809600   \n",
       "29185                                            Fun toy      1400112000   \n",
       "29186   and now the play set has a nice climbing feature      1510531200   \n",
       "29187  my brother said she liked it and I haven't see...      1514851200   \n",
       "29188                               Ninja fan will love!      1469836800   \n",
       "\n",
       "       vote image                                         style    category  \n",
       "0       2.0   NaN                      {'Size:': ' Polaris H4'}  automotive  \n",
       "1       NaN   NaN                                           NaN  automotive  \n",
       "2       NaN   NaN                                           NaN  automotive  \n",
       "3       NaN   NaN  {'Color:': ' Clear', 'Style:': ' 45 Degree'}  automotive  \n",
       "4       NaN   NaN                                           NaN  automotive  \n",
       "...     ...   ...                                           ...         ...  \n",
       "29184   NaN   NaN                                           NaN        toys  \n",
       "29185   NaN   NaN                                           NaN        toys  \n",
       "29186   NaN   NaN                                           NaN        toys  \n",
       "29187   NaN   NaN               {'Style:': ' Standard Version'}        toys  \n",
       "29188   NaN   NaN                                           NaN        toys  \n",
       "\n",
       "[29189 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('Train.csv')\n",
    "test=pd.read_csv('Test.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "      <th>style</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>11 12, 2016</td>\n",
       "      <td>C413C78E10E54C5DB41837889F36C1E8</td>\n",
       "      <td>565D194F38B1CC3F806EE677C61F639C</td>\n",
       "      <td>465E154EC79AFFAB5EB2607198B21433</td>\n",
       "      <td>all of the reviews for this product are fake.</td>\n",
       "      <td>All fake reviews, beware.</td>\n",
       "      <td>1478908800</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Size:': ' Polaris H4'}</td>\n",
       "      <td>automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12 6, 2016</td>\n",
       "      <td>490AE37808EFEE3AF4FE6DEBDEB5A4C8</td>\n",
       "      <td>0D66512A0A7F580523AB996378DF0F14</td>\n",
       "      <td>760C63E8E5E8DC3FAA01878D37BA5678</td>\n",
       "      <td>wrong part. our fault.</td>\n",
       "      <td>One Star</td>\n",
       "      <td>1480982400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>09 17, 2014</td>\n",
       "      <td>74A9FA5A64449BEE2A2E8E3F62872F0F</td>\n",
       "      <td>A0E45600FF2C5A779CB4314F379C253A</td>\n",
       "      <td>C6E4DD5C1C4EC09E90182644ED6CA9EF</td>\n",
       "      <td>this wire set it really sucks!!!</td>\n",
       "      <td>One Star</td>\n",
       "      <td>1410912000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>06 11, 2016</td>\n",
       "      <td>EB561158A2829D98B467FE03CC1E45F1</td>\n",
       "      <td>37AB9A82470595E0ACB88BAC48C150EE</td>\n",
       "      <td>F4892A77EA45C52F40AB17ED537EF9FF</td>\n",
       "      <td>first use, it leaked instantly. even at 5 buck...</td>\n",
       "      <td>One Star</td>\n",
       "      <td>1465603200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Color:': ' Clear', 'Style:': ' 45 Degree'}</td>\n",
       "      <td>automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12 23, 2017</td>\n",
       "      <td>5045D801332850D21618DD13A697CD9B</td>\n",
       "      <td>5772FF30428EEB8E0258C1A53CA2EC50</td>\n",
       "      <td>522F0BBFF2B47F1D63FF781A0AB1D079</td>\n",
       "      <td>didn't fit</td>\n",
       "      <td>One Star</td>\n",
       "      <td>1513987200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>automotive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime                        reviewerID  \\\n",
       "0        1     False  11 12, 2016  C413C78E10E54C5DB41837889F36C1E8   \n",
       "1        1      True   12 6, 2016  490AE37808EFEE3AF4FE6DEBDEB5A4C8   \n",
       "2        1      True  09 17, 2014  74A9FA5A64449BEE2A2E8E3F62872F0F   \n",
       "3        1      True  06 11, 2016  EB561158A2829D98B467FE03CC1E45F1   \n",
       "4        1      True  12 23, 2017  5045D801332850D21618DD13A697CD9B   \n",
       "\n",
       "                               asin                      reviewerName  \\\n",
       "0  565D194F38B1CC3F806EE677C61F639C  465E154EC79AFFAB5EB2607198B21433   \n",
       "1  0D66512A0A7F580523AB996378DF0F14  760C63E8E5E8DC3FAA01878D37BA5678   \n",
       "2  A0E45600FF2C5A779CB4314F379C253A  C6E4DD5C1C4EC09E90182644ED6CA9EF   \n",
       "3  37AB9A82470595E0ACB88BAC48C150EE  F4892A77EA45C52F40AB17ED537EF9FF   \n",
       "4  5772FF30428EEB8E0258C1A53CA2EC50  522F0BBFF2B47F1D63FF781A0AB1D079   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0      all of the reviews for this product are fake.   \n",
       "1                             wrong part. our fault.   \n",
       "2                   this wire set it really sucks!!!   \n",
       "3  first use, it leaked instantly. even at 5 buck...   \n",
       "4                                         didn't fit   \n",
       "\n",
       "                     summary  unixReviewTime  vote image  \\\n",
       "0  All fake reviews, beware.      1478908800   2.0   NaN   \n",
       "1                   One Star      1480982400   NaN   NaN   \n",
       "2                   One Star      1410912000   NaN   NaN   \n",
       "3                   One Star      1465603200   NaN   NaN   \n",
       "4                   One Star      1513987200   NaN   NaN   \n",
       "\n",
       "                                          style    category  \n",
       "0                      {'Size:': ' Polaris H4'}  automotive  \n",
       "1                                           NaN  automotive  \n",
       "2                                           NaN  automotive  \n",
       "3  {'Color:': ' Clear', 'Style:': ' 45 Degree'}  automotive  \n",
       "4                                           NaN  automotive  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing: to lower, and remove NANs, at last concatenate features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(train:pd.DataFrame):\n",
    "    train=train.drop(columns=[\"reviewTime\",\"reviewerID\",\"asin\",\"reviewerName\",\"unixReviewTime\",\"vote\",\"image\"])\n",
    "    train['style'].fillna('')\n",
    "    train['summary'].fillna('')\n",
    "    train['summary']=train['summary'].astype(str)\n",
    "    train['style']=train['style'].astype(str)\n",
    "    train['summary'] = train['summary'].apply(lambda x: x.lower())\n",
    "    train['reviewText']=train['reviewText'].apply(lambda x: x.lower())\n",
    "    train['style']=train['style'].apply(lambda x: x.lower())\n",
    "    train['alltext']=train['summary'].fillna('')+' '+train['reviewText'].fillna('')+' '+train['style'].fillna('')\n",
    "    train['allreview']=train['summary'].fillna('')+' '+train['reviewText'].fillna('')\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>style</th>\n",
       "      <th>category</th>\n",
       "      <th>alltext</th>\n",
       "      <th>allreview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>all of the reviews for this product are fake.</td>\n",
       "      <td>all fake reviews, beware.</td>\n",
       "      <td>{'size:': ' polaris h4'}</td>\n",
       "      <td>automotive</td>\n",
       "      <td>all fake reviews, beware. all of the reviews f...</td>\n",
       "      <td>all fake reviews, beware. all of the reviews f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>wrong part. our fault.</td>\n",
       "      <td>one star</td>\n",
       "      <td>nan</td>\n",
       "      <td>automotive</td>\n",
       "      <td>one star wrong part. our fault. nan</td>\n",
       "      <td>one star wrong part. our fault.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>this wire set it really sucks!!!</td>\n",
       "      <td>one star</td>\n",
       "      <td>nan</td>\n",
       "      <td>automotive</td>\n",
       "      <td>one star this wire set it really sucks!!! nan</td>\n",
       "      <td>one star this wire set it really sucks!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>first use, it leaked instantly. even at 5 buck...</td>\n",
       "      <td>one star</td>\n",
       "      <td>{'color:': ' clear', 'style:': ' 45 degree'}</td>\n",
       "      <td>automotive</td>\n",
       "      <td>one star first use, it leaked instantly. even ...</td>\n",
       "      <td>one star first use, it leaked instantly. even ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>didn't fit</td>\n",
       "      <td>one star</td>\n",
       "      <td>nan</td>\n",
       "      <td>automotive</td>\n",
       "      <td>one star didn't fit nan</td>\n",
       "      <td>one star didn't fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29184</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>this is the same plush toy that the official d...</td>\n",
       "      <td>well constructed, very soft</td>\n",
       "      <td>nan</td>\n",
       "      <td>toys</td>\n",
       "      <td>well constructed, very soft this is the same p...</td>\n",
       "      <td>well constructed, very soft this is the same p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29185</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>my grandson loved this. it is a great toy, he ...</td>\n",
       "      <td>fun toy</td>\n",
       "      <td>nan</td>\n",
       "      <td>toys</td>\n",
       "      <td>fun toy my grandson loved this. it is a great ...</td>\n",
       "      <td>fun toy my grandson loved this. it is a great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29186</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>my kiddo loves them! we are a rock climbing fa...</td>\n",
       "      <td>and now the play set has a nice climbing feature</td>\n",
       "      <td>nan</td>\n",
       "      <td>toys</td>\n",
       "      <td>and now the play set has a nice climbing featu...</td>\n",
       "      <td>and now the play set has a nice climbing featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29187</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>i bought this for my niece (age 2) and mailed ...</td>\n",
       "      <td>my brother said she liked it and i haven't see...</td>\n",
       "      <td>{'style:': ' standard version'}</td>\n",
       "      <td>toys</td>\n",
       "      <td>my brother said she liked it and i haven't see...</td>\n",
       "      <td>my brother said she liked it and i haven't see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29188</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>my daughter will love this! she's a huge ninja...</td>\n",
       "      <td>ninja fan will love!</td>\n",
       "      <td>nan</td>\n",
       "      <td>toys</td>\n",
       "      <td>ninja fan will love! my daughter will love thi...</td>\n",
       "      <td>ninja fan will love! my daughter will love thi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29189 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       overall  verified                                         reviewText  \\\n",
       "0            1     False      all of the reviews for this product are fake.   \n",
       "1            1      True                             wrong part. our fault.   \n",
       "2            1      True                   this wire set it really sucks!!!   \n",
       "3            1      True  first use, it leaked instantly. even at 5 buck...   \n",
       "4            1      True                                         didn't fit   \n",
       "...        ...       ...                                                ...   \n",
       "29184        5      True  this is the same plush toy that the official d...   \n",
       "29185        5      True  my grandson loved this. it is a great toy, he ...   \n",
       "29186        5      True  my kiddo loves them! we are a rock climbing fa...   \n",
       "29187        5      True  i bought this for my niece (age 2) and mailed ...   \n",
       "29188        5      True  my daughter will love this! she's a huge ninja...   \n",
       "\n",
       "                                                 summary  \\\n",
       "0                              all fake reviews, beware.   \n",
       "1                                               one star   \n",
       "2                                               one star   \n",
       "3                                               one star   \n",
       "4                                               one star   \n",
       "...                                                  ...   \n",
       "29184                        well constructed, very soft   \n",
       "29185                                            fun toy   \n",
       "29186   and now the play set has a nice climbing feature   \n",
       "29187  my brother said she liked it and i haven't see...   \n",
       "29188                               ninja fan will love!   \n",
       "\n",
       "                                              style    category  \\\n",
       "0                          {'size:': ' polaris h4'}  automotive   \n",
       "1                                               nan  automotive   \n",
       "2                                               nan  automotive   \n",
       "3      {'color:': ' clear', 'style:': ' 45 degree'}  automotive   \n",
       "4                                               nan  automotive   \n",
       "...                                             ...         ...   \n",
       "29184                                           nan        toys   \n",
       "29185                                           nan        toys   \n",
       "29186                                           nan        toys   \n",
       "29187               {'style:': ' standard version'}        toys   \n",
       "29188                                           nan        toys   \n",
       "\n",
       "                                                 alltext  \\\n",
       "0      all fake reviews, beware. all of the reviews f...   \n",
       "1                    one star wrong part. our fault. nan   \n",
       "2          one star this wire set it really sucks!!! nan   \n",
       "3      one star first use, it leaked instantly. even ...   \n",
       "4                                one star didn't fit nan   \n",
       "...                                                  ...   \n",
       "29184  well constructed, very soft this is the same p...   \n",
       "29185  fun toy my grandson loved this. it is a great ...   \n",
       "29186  and now the play set has a nice climbing featu...   \n",
       "29187  my brother said she liked it and i haven't see...   \n",
       "29188  ninja fan will love! my daughter will love thi...   \n",
       "\n",
       "                                               allreview  \n",
       "0      all fake reviews, beware. all of the reviews f...  \n",
       "1                        one star wrong part. our fault.  \n",
       "2              one star this wire set it really sucks!!!  \n",
       "3      one star first use, it leaked instantly. even ...  \n",
       "4                                    one star didn't fit  \n",
       "...                                                  ...  \n",
       "29184  well constructed, very soft this is the same p...  \n",
       "29185  fun toy my grandson loved this. it is a great ...  \n",
       "29186  and now the play set has a nice climbing featu...  \n",
       "29187  my brother said she liked it and i haven't see...  \n",
       "29188  ninja fan will love! my daughter will love thi...  \n",
       "\n",
       "[29189 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=preprocess(train)\n",
    "test = preprocess(test)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Begin to implement the binary classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "construct features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29189, 4000) (4500, 4000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,HashingVectorizer,TfidfTransformer\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=\"english\",max_features=4000)\n",
    "transformer =TfidfTransformer()\n",
    "\n",
    "features_bin= vectorizer.fit_transform(train[\"allreview\"].values)\n",
    "features_bin = transformer.fit_transform(features_bin)\n",
    "features_bin = features_bin.toarray()\n",
    "test_features_bin= vectorizer.transform(test[\"allreview\"].values)\n",
    "test_features_bin = transformer.fit_transform(test_features_bin)\n",
    "test_features_bin=test_features_bin.toarray()\n",
    "\n",
    "print(features_bin.shape,test_features_bin.shape)\n",
    "\n",
    "labels_bin1 =  (train[\"overall\"]>1).values.astype(np.int32)\n",
    "labels_bin2 =  (train[\"overall\"]>2).values.astype(np.int32)\n",
    "labels_bin3 =  (train[\"overall\"]>3).values.astype(np.int32)\n",
    "labels_bin4 =  (train[\"overall\"]>4).values.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA, uncomment this 3 lines to perform PCA analysis\n",
    "#from sklearn.decomposition import PCA,TruncatedSVD\n",
    "\n",
    "#svd = TruncatedSVD(n_components=2000)\n",
    "#features = svd.fit_transform(features_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"features2000Tfidf_bin.npy\",features_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = np.load(\"features2000Tfidf_bin.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, f1_score,silhouette_score, adjusted_rand_score\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval_mat(y_true,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    print(\"tn, fp, fn, tp:\",tn, fp, fn, tp)\n",
    "    print(\"fpr,tpr,thresholds:\",fpr, tpr, thresholds)\n",
    "    print(\"roc_auc\",roc_auc)\n",
    "    print(\"macro_f1\",macro_f1)\n",
    "    return tn, fp, fn, tp,fpr, tpr, thresholds,roc_auc,macro_f1\n",
    "\n",
    "def binary_classification(model,X,y,test_file_name:str):\n",
    "    # i could also use the models below, I just uncomment it.\n",
    "    \n",
    "    #model = DecisionTreeClassifier()\n",
    "    #model = RandomForestClassifier(n_estimators=100, class_weight='balanced',verbose=1,n_jobs=20)\n",
    "    #model = LogisticRegression(max_iter=300,class_weight=\"balanced\")\n",
    "    #model = svm.SVC(kernel='linear', C=1, gamma='auto')\n",
    "    #model = MLPClassifier(hidden_layer_sizes=(512,256), max_iter=500, alpha=0.0001, solver='adam', random_state=0, tol=0.0001,verbose=True)\n",
    "    \n",
    "    # log_reg = LogisticRegression()\n",
    "    #dtc = DecisionTreeClassifier(class_weight='balanced')\n",
    "    #svc = SVC(kernel='linear', class_weight='balanced')\n",
    "    #classifiers = [('logistic regression', log_reg), ('decision tree', dtc), ('SVM', svc)]\n",
    "    #model = VotingClassifier(estimators=classifiers, voting='hard')\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    f1=[]\n",
    "    for idx,(train_index, test_index) in enumerate(kf.split(X)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(\"fold:{}\".format(idx))\n",
    "        tn, fp, fn, tp,fpr, tpr, thresholds,roc_auc,macro_f1=eval_mat(y_pred,y_test)\n",
    "        f1.append(macro_f1)\n",
    "    print(\"mean_f1 is :\",np.mean(f1))\n",
    "    test_predicted = model.predict(test_features_bin)\n",
    "    test_submission = pd.DataFrame({'id':np.arange(len(test_predicted)), 'predicted':test_predicted})\n",
    "    test_submission.to_csv(test_file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the **Inbalanced** distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7959162698276748"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_bin1.astype(np.int32).sum()/len(labels_bin1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5917640206927267"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_bin2.astype(np.int32).sum()/len(labels_bin2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39093494124498956"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_bin3.astype(np.int32).sum()/len(labels_bin3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1932919935592175"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_bin4.astype(np.int32).sum()/len(labels_bin4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm trying to use GirdSearchCV or RandomizedSearchCV to find the best combination of hyperparameters, but it spend too much time.\n",
    "\n",
    "**and it will cause ipykernel to fail.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters = {'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "#               'C': [0.1, 1, 10],\n",
    "#               'fit_intercept': [True, False],\n",
    "#               'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "#               'multi_class': ['ovr', 'multinomial', 'auto'],\n",
    "#               'class_weight': [None, 'balanced']}\n",
    "# # Define the logistic regression model\n",
    "# clf = LogisticRegression()\n",
    "\n",
    "# # Perform a grid search with cross-validation to find the best hyperparameters\n",
    "# search =RandomizedSearchCV(clf, hyperparameters, n_iter=100, random_state=42, cv=5, scoring='f1_macro',verbose=2,n_jobs=10)\n",
    "# search.fit(features_bin, labels_bin1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(\"Best hyperparameters: \", search.best_params_)\\nprint(\"Best Score: \", search.best_score_)'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(\"Best hyperparameters: \", search.best_params_)\n",
    "print(\"Best Score: \", search.best_score_)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:0\n",
      "tn, fp, fn, tp: 939 805 222 3872\n",
      "fpr,tpr,thresholds: [0.         0.46158257 1.        ] [0.        0.9457743 1.       ] [2 1 0]\n",
      "roc_auc 0.7420958675259834\n",
      "macro_f1 0.76469059455242\n",
      "fold:1\n",
      "tn, fp, fn, tp: 961 691 255 3931\n",
      "fpr,tpr,thresholds: [0.         0.41828087 1.        ] [0.         0.93908266 1.        ] [2 1 0]\n",
      "roc_auc 0.7604008924016293\n",
      "macro_f1 0.7813755277628934\n",
      "fold:2\n",
      "tn, fp, fn, tp: 944 716 271 3907\n",
      "fpr,tpr,thresholds: [0.        0.4313253 1.       ] [0.         0.93513643 1.        ] [2 1 0]\n",
      "roc_auc 0.7519055638542682\n",
      "macro_f1 0.7722746525839455\n",
      "fold:3\n",
      "tn, fp, fn, tp: 935 708 243 3952\n",
      "fpr,tpr,thresholds: [0.         0.43091905 1.        ] [0.        0.9420739 1.       ] [2 1 0]\n",
      "roc_auc 0.755577423489837\n",
      "macro_f1 0.7777442753599837\n",
      "fold:4\n",
      "tn, fp, fn, tp: 962 784 225 3866\n",
      "fpr,tpr,thresholds: [0.         0.44902635 1.        ] [0.         0.94500122 1.        ] [2 1 0]\n",
      "roc_auc 0.7479874381307501\n",
      "macro_f1 0.7702753088433116\n",
      "mean_f1 is : 0.7732720718205108\n"
     ]
    }
   ],
   "source": [
    "binary_classification(LogisticRegression(max_iter=300,class_weight=\"balanced\"),features_bin, labels_bin1,\"test_submission_part_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:0\n",
      "tn, fp, fn, tp: 1944 645 503 2746\n",
      "fpr,tpr,thresholds: [0.         0.24913094 1.        ] [0.         0.84518313 1.        ] [2 1 0]\n",
      "roc_auc 0.7980260973427246\n",
      "macro_f1 0.7995748681780337\n",
      "fold:1\n",
      "tn, fp, fn, tp: 1883 718 493 2744\n",
      "fpr,tpr,thresholds: [0.         0.27604767 1.        ] [0.         0.84769849 1.        ] [2 1 0]\n",
      "roc_auc 0.7858254061405769\n",
      "macro_f1 0.7879537408127544\n",
      "fold:2\n",
      "tn, fp, fn, tp: 1808 666 537 2827\n",
      "fpr,tpr,thresholds: [0.         0.26919968 1.        ] [0.         0.84036861 1.        ] [2 1 0]\n",
      "roc_auc 0.7855844660810118\n",
      "macro_f1 0.7874609954284125\n",
      "fold:3\n",
      "tn, fp, fn, tp: 1881 684 466 2807\n",
      "fpr,tpr,thresholds: [0.         0.26666667 1.        ] [0.         0.85762298 1.        ] [2 1 0]\n",
      "roc_auc 0.7954781545982279\n",
      "macro_f1 0.7979308689228469\n",
      "fold:4\n",
      "tn, fp, fn, tp: 1924 616 477 2820\n",
      "fpr,tpr,thresholds: [0.         0.24251969 1.        ] [0.         0.85532302 1.        ] [2 1 0]\n",
      "roc_auc 0.8064016679443732\n",
      "macro_f1 0.8082274748162281\n",
      "mean_f1 is : 0.7962295896316551\n"
     ]
    }
   ],
   "source": [
    "binary_classification(LogisticRegression(max_iter=300,class_weight=\"balanced\"),features_bin,labels_bin2,\"test_submission_part_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:0\n",
      "tn, fp, fn, tp: 2836 485 722 1795\n",
      "fpr,tpr,thresholds: [0.         0.14604035 1.        ] [0.         0.71315058 1.        ] [2 1 0]\n",
      "roc_auc 0.7835551133951282\n",
      "macro_f1 0.7864614286385743\n",
      "fold:1\n",
      "tn, fp, fn, tp: 2894 395 684 1865\n",
      "fpr,tpr,thresholds: [0.         0.12009729 1.        ] [0.         0.73165947 1.        ] [2 1 0]\n",
      "roc_auc 0.8057810901466553\n",
      "macro_f1 0.8092503670805822\n",
      "fold:2\n",
      "tn, fp, fn, tp: 2863 443 705 1827\n",
      "fpr,tpr,thresholds: [0.         0.13399879 1.        ] [0.         0.72156398 1.        ] [2 1 0]\n",
      "roc_auc 0.7937825954820046\n",
      "macro_f1 0.7969634173133903\n",
      "fold:3\n",
      "tn, fp, fn, tp: 2898 427 649 1864\n",
      "fpr,tpr,thresholds: [0.         0.12842105 1.        ] [0.         0.74174294 1.        ] [2 1 0]\n",
      "roc_auc 0.8066609420487151\n",
      "macro_f1 0.8097212838738381\n",
      "fold:4\n",
      "tn, fp, fn, tp: 2840 466 687 1844\n",
      "fpr,tpr,thresholds: [0.         0.14095584 1.        ] [0.         0.72856578 1.        ] [2 1 0]\n",
      "roc_auc 0.7938049732022258\n",
      "macro_f1 0.7965430652302112\n",
      "mean_f1 is : 0.7997879124273192\n"
     ]
    }
   ],
   "source": [
    "binary_classification(LogisticRegression(solver='liblinear',\n",
    "                                         penalty= 'l1',\n",
    "                                         multi_class= 'ovr',\n",
    "                                         max_iter= 300, \n",
    "                                         class_weight= 'balanced',\n",
    "                                         C=1,\n",
    "                                         random_state=1),features_bin,labels_bin3,\"test_submission_part_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 135 candidates, totalling 675 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/model_selection/_search.py:305: UserWarning: The total space of parameters 135 is smaller than n_iter=200. Running 135 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "360 fits failed out of a total of 675.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.77964763 0.77964763 0.77968513 0.77964763 0.77964763        nan\n",
      "        nan 0.77821113        nan 0.7780228         nan        nan\n",
      "        nan        nan        nan 0.77964763 0.77964763 0.77968513\n",
      " 0.77964763 0.77964763        nan        nan 0.77821113        nan\n",
      " 0.7780228         nan        nan        nan        nan        nan\n",
      " 0.77964763 0.77964763 0.77968513 0.77964763 0.77964763        nan\n",
      "        nan 0.77821113        nan 0.7780228         nan        nan\n",
      "        nan        nan        nan 0.77898274 0.77902056 0.77892203\n",
      " 0.77898274 0.77898274        nan        nan 0.78006916        nan\n",
      " 0.78019632        nan        nan        nan        nan        nan\n",
      " 0.77898274 0.77902056 0.77892203 0.77898274 0.77898274        nan\n",
      "        nan 0.78006916        nan 0.78019632        nan        nan\n",
      "        nan        nan        nan 0.77898274 0.77902056 0.77892203\n",
      " 0.77901539 0.77898274        nan        nan 0.78006916        nan\n",
      " 0.78019632        nan        nan        nan        nan        nan\n",
      " 0.77857465 0.77850182 0.77857465 0.77857465 0.77857465        nan\n",
      "        nan 0.77868963        nan 0.7785349         nan        nan\n",
      "        nan        nan        nan 0.77857465 0.77850182 0.77857465\n",
      " 0.77857465 0.77857465        nan        nan 0.77868963        nan\n",
      " 0.7785349         nan        nan        nan        nan        nan\n",
      " 0.77857465 0.77850182 0.77857465 0.77857465 0.77857465        nan\n",
      "        nan 0.77872683        nan 0.7785349         nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=LogisticRegression(), n_iter=200, n_jobs=10,\n",
       "                   param_distributions={&#x27;C&#x27;: [0.75, 1, 1.25],\n",
       "                                        &#x27;class_weight&#x27;: [&#x27;balanced&#x27;],\n",
       "                                        &#x27;max_iter&#x27;: [100, 200, 300],\n",
       "                                        &#x27;multi_class&#x27;: [&#x27;ovr&#x27;],\n",
       "                                        &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;],\n",
       "                                        &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;,\n",
       "                                                   &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                                   &#x27;saga&#x27;]},\n",
       "                   scoring=&#x27;f1_macro&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=LogisticRegression(), n_iter=200, n_jobs=10,\n",
       "                   param_distributions={&#x27;C&#x27;: [0.75, 1, 1.25],\n",
       "                                        &#x27;class_weight&#x27;: [&#x27;balanced&#x27;],\n",
       "                                        &#x27;max_iter&#x27;: [100, 200, 300],\n",
       "                                        &#x27;multi_class&#x27;: [&#x27;ovr&#x27;],\n",
       "                                        &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;],\n",
       "                                        &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;,\n",
       "                                                   &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                                   &#x27;saga&#x27;]},\n",
       "                   scoring=&#x27;f1_macro&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LogisticRegression(), n_iter=200, n_jobs=10,\n",
       "                   param_distributions={'C': [0.75, 1, 1.25],\n",
       "                                        'class_weight': ['balanced'],\n",
       "                                        'max_iter': [100, 200, 300],\n",
       "                                        'multi_class': ['ovr'],\n",
       "                                        'penalty': ['l2', 'l1', 'elasticnet'],\n",
       "                                        'solver': ['newton-cg', 'lbfgs',\n",
       "                                                   'liblinear', 'sag',\n",
       "                                                   'saga']},\n",
       "                   scoring='f1_macro', verbose=2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {'penalty': ['l2',\"l1\",'elasticnet'],\n",
    "              'C': [0.75, 1, 1.25],\n",
    "              'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "              'max_iter':[100,200,300],\n",
    "              'multi_class': ['ovr'],\n",
    "              'class_weight': ['balanced']}\n",
    "# Define the logistic regression model\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Perform a grid search with cross-validation to find the best hyperparameters\n",
    "search =RandomizedSearchCV(clf, hyperparameters, n_iter=200, cv=5, scoring='f1_macro',verbose=2,n_jobs=10)\n",
    "search.fit(features_bin, labels_bin3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'solver': 'saga', 'penalty': 'l1', 'multi_class': 'ovr', 'max_iter': 100, 'class_weight': 'balanced', 'C': 1}\n",
      "Best Score:  0.7801963230953796\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters: \", search.best_params_)\n",
    "print(\"Best Score: \", search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:0\n",
      "tn, fp, fn, tp: 3868 287 851 832\n",
      "fpr,tpr,thresholds: [0.         0.06907341 1.        ] [0.         0.49435532 1.        ] [2 1 0]\n",
      "roc_auc 0.7126409561746152\n",
      "macro_f1 0.7328108629062888\n",
      "fold:1\n",
      "tn, fp, fn, tp: 3876 251 843 868\n",
      "fpr,tpr,thresholds: [0.       0.060819 1.      ] [0.         0.50730567 1.        ] [2 1 0]\n",
      "roc_auc 0.7232433361746433\n",
      "macro_f1 0.744877922903806\n",
      "fold:2\n",
      "tn, fp, fn, tp: 3838 251 866 883\n",
      "fpr,tpr,thresholds: [0.        0.0613842 1.       ] [0.         0.50485992 1.        ] [2 1 0]\n",
      "roc_auc 0.7217378592189982\n",
      "macro_f1 0.742761748922169\n",
      "fold:3\n",
      "tn, fp, fn, tp: 3869 275 807 887\n",
      "fpr,tpr,thresholds: [0.       0.066361 1.      ] [0.         0.52361275 1.        ] [2 1 0]\n",
      "roc_auc 0.7286258735122372\n",
      "macro_f1 0.7492363612111512\n",
      "fold:4\n",
      "tn, fp, fn, tp: 3907 267 822 841\n",
      "fpr,tpr,thresholds: [0.         0.06396742 1.        ] [0.         0.50571257 1.        ] [2 1 0]\n",
      "roc_auc 0.7208725751516777\n",
      "macro_f1 0.742341381487059\n",
      "mean_f1 is : 0.7424056554860947\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  44.5s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=sag; total time=  30.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.2s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=saga; total time= 1.1min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=sag; total time=  29.1s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=saga; total time= 1.1min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=sag; total time=  32.2s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  37.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  25.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=saga; total time=  25.9s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=saga; total time= 1.4min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=saga; total time=  22.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.2s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=sag; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=saga; total time= 1.3min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=saga; total time=  25.8s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=saga; total time= 1.2min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear; total time=   2.6s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=sag; total time=  32.1s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  39.6s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  22.0s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=liblinear; total time=   2.7s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=liblinear; total time=   2.7s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=sag; total time=  44.1s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.7s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  41.2s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  22.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=liblinear; total time=   2.6s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=sag; total time=  31.0s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=sag; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg; total time= 1.0min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=saga; total time=  25.2s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.5s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  35.2s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  22.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=saga; total time=  24.2s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=saga; total time= 1.0min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=sag; total time=  36.0s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=saga; total time= 1.0min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=sag; total time=  31.8s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=saga; total time= 1.4min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=saga; total time=  25.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.7s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  37.9s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  24.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=liblinear; total time=   2.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=saga; total time=  24.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=saga; total time= 1.3min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=saga; total time=  24.7s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=saga; total time= 1.7min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=saga; total time=  25.0s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  43.7s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  21.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=sag; total time=  30.0s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=saga; total time=  25.1s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.5s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  58.1s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=saga; total time=  22.6s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.5s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  39.7s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  20.9s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=saga; total time=  26.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.5s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  35.0s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  24.8s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=saga; total time=  25.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=saga; total time= 1.1min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=sag; total time=  41.0s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.7s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  38.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  24.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=liblinear; total time=   2.7s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=sag; total time=  36.2s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.7s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  38.0s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  21.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=liblinear; total time=   2.9s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=sag; total time=  29.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  42.9s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  22.0s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=sag; total time=  30.8s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  41.0s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  26.1s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=sag; total time=  38.8s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  38.8s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  23.0s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=liblinear; total time=   2.7s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=liblinear; total time=   2.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=sag; total time=  42.7s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.5s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  42.2s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear; total time=   3.7s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=sag; total time=  34.6s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.2s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=saga; total time= 1.0min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=liblinear; total time=   3.6s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=sag; total time=  29.9s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.2s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=saga; total time=  49.9s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=liblinear; total time=   3.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=liblinear; total time=   3.6s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=liblinear; total time=   3.7s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=sag; total time=  32.7s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  38.0s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  22.2s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=saga; total time=  25.7s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=sag; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  37.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  24.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=liblinear; total time=   2.9s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=sag; total time=  34.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.7s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  39.1s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  23.0s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=liblinear; total time=   2.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=sag; total time=  27.0s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=saga; total time= 1.4min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=saga; total time=  23.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=saga; total time= 1.3min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=saga; total time=  25.1s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=saga; total time=  26.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  42.0s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  25.1s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=sag; total time=  42.0s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.5s\n"
     ]
    }
   ],
   "source": [
    "binary_classification(LogisticRegression(max_iter=300,class_weight=\"balanced\"),features_bin,labels_bin4,\"test_submission_part_4.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels_mc = train[\"overall\"].values-1\n",
    "features_mc = features_bin\n",
    "test_features_mc = test_features_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  39.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear; total time=   4.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=sag; total time=  34.6s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.2s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=saga; total time=  48.6s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  24.0s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=saga; total time=  23.2s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.5s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  40.9s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=liblinear; total time=   3.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=liblinear; total time=   3.7s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=sag; total time=  34.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.7s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=saga; total time=  55.1s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear; total time=   3.7s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear; total time=   3.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=sag; total time=  35.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=saga; total time= 1.2min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=sag; total time=  30.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.9s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  40.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  25.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=sag; total time=  35.9s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.7s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  40.0s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  21.9s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear; total time=   2.7s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=sag; total time=  28.0s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=sag; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  40.2s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  22.1s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=liblinear; total time=   2.7s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=sag; total time=  31.9s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=saga; total time= 2.6min\n"
     ]
    }
   ],
   "source": [
    "def eval_mat(y_true,y_pred):\n",
    "    confusion_mat = confusion_matrix(y_true, y_pred)\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    print(\"confusion_mat:\",confusion_mat)\n",
    "    print(\"macro_f1\",macro_f1)\n",
    "    return confusion_mat,macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multicalss_clsfication(X,y,model,test_file_name):\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    for idx,(train_index, test_index) in enumerate(kf.split(X)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(\"fold:{}\".format(idx))\n",
    "        eval_mat(y_pred,y_test)\n",
    "    test_predicted = model.predict(test_features_bin)\n",
    "    test_submission = pd.DataFrame({'id':np.arange(len(test_predicted)), 'predicted':test_predicted+1})\n",
    "    test_submission.to_csv(test_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/model_selection/_search.py:305: UserWarning: The total space of parameters 90 is smaller than n_iter=200. Running 90 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "300 fits failed out of a total of 450.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n",
      "    multi_class = _check_multi_class(self.multi_class, solver, len(self.classes_))\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 90, in _check_multi_class\n",
      "    raise ValueError(\"Solver %s does not support a multinomial backend.\" % solver)\n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/xingjiandiao/Desktop/ML/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.47865669 0.47859036        nan 0.4786668  0.47869218        nan\n",
      "        nan        nan        nan 0.47672431        nan        nan\n",
      "        nan        nan        nan 0.47902596 0.47785496        nan\n",
      " 0.47900226 0.47897145        nan        nan        nan        nan\n",
      " 0.47612534        nan        nan        nan        nan        nan\n",
      " 0.47503209 0.47490608        nan 0.47497021 0.47503162        nan\n",
      "        nan        nan        nan 0.47815115        nan        nan\n",
      "        nan        nan        nan 0.47537442 0.47532021        nan\n",
      " 0.47539294 0.47537482        nan        nan        nan        nan\n",
      " 0.47719998        nan        nan        nan        nan        nan\n",
      " 0.47286506 0.47404539        nan 0.47286639 0.47283576        nan\n",
      "        nan        nan        nan 0.4757532         nan        nan\n",
      "        nan        nan        nan 0.47279389 0.47381739        nan\n",
      " 0.47265953 0.47279433        nan        nan        nan        nan\n",
      " 0.47521826        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=LogisticRegression(), n_iter=200, n_jobs=10,\n",
       "                   param_distributions={&#x27;C&#x27;: [0.75, 1, 1.25],\n",
       "                                        &#x27;class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                                        &#x27;max_iter&#x27;: [100],\n",
       "                                        &#x27;multi_class&#x27;: [&#x27;multinomial&#x27;],\n",
       "                                        &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;],\n",
       "                                        &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;,\n",
       "                                                   &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                                   &#x27;saga&#x27;]},\n",
       "                   scoring=&#x27;f1_macro&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=LogisticRegression(), n_iter=200, n_jobs=10,\n",
       "                   param_distributions={&#x27;C&#x27;: [0.75, 1, 1.25],\n",
       "                                        &#x27;class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                                        &#x27;max_iter&#x27;: [100],\n",
       "                                        &#x27;multi_class&#x27;: [&#x27;multinomial&#x27;],\n",
       "                                        &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;],\n",
       "                                        &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;,\n",
       "                                                   &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                                   &#x27;saga&#x27;]},\n",
       "                   scoring=&#x27;f1_macro&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LogisticRegression(), n_iter=200, n_jobs=10,\n",
       "                   param_distributions={'C': [0.75, 1, 1.25],\n",
       "                                        'class_weight': ['balanced', None],\n",
       "                                        'max_iter': [100],\n",
       "                                        'multi_class': ['multinomial'],\n",
       "                                        'penalty': ['l2', 'l1', 'elasticnet'],\n",
       "                                        'solver': ['newton-cg', 'lbfgs',\n",
       "                                                   'liblinear', 'sag',\n",
       "                                                   'saga']},\n",
       "                   scoring='f1_macro', verbose=2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {'penalty': ['l2',\"l1\",'elasticnet'],\n",
    "              'C': [0.75, 1, 1.25],\n",
    "              'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "              'max_iter':[100],\n",
    "              'multi_class': ['multinomial'],\n",
    "              'class_weight': ['balanced',None]}\n",
    "# Define the logistic regression model\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Perform a grid search with cross-validation to find the best hyperparameters\n",
    "search =RandomizedSearchCV(clf, hyperparameters, n_iter=200, cv=5, scoring='f1_macro',verbose=2,n_jobs=10)\n",
    "search.fit(features_mc, labels_mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'solver': 'newton-cg', 'penalty': 'l2', 'multi_class': 'multinomial', 'max_iter': 100, 'class_weight': None, 'C': 0.75}\n",
      "Best Score:  0.47902595968920886\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg; total time= 1.1min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=saga; total time=  24.1s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  38.9s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  23.5s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=saga; total time=  24.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.5s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  39.1s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  21.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=saga; total time=  25.6s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  38.9s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  26.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=saga; total time=  23.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=saga; total time= 1.3min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=saga; total time=  22.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=saga; total time= 1.3min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=saga; total time=  23.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=saga; total time= 1.3min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=saga; total time=  22.8s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=saga; total time= 1.5min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=saga; total time=  24.8s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=saga; total time= 1.6min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=saga; total time=  24.7s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=sag; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=saga; total time=  57.9s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.8min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.3min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.3min\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  56.5s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   1.8s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   2.3s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 2.2min\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 3.3min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.3min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.7s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 4.4min\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.4min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.7min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  46.9s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 2.4min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.5min\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  50.1s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 2.1min\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.3min\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.6s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time= 1.3min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 2.0min\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.3min\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  55.6s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   1.9s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 2.4min\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.5s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.4min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  49.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 2.2min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 4.4min\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 4.1min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.3min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 6.4min\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  42.7s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear; total time=   3.7s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=sag; total time=  32.6s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.2s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=saga; total time=  58.5s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=liblinear; total time=   3.8s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=sag; total time=  35.0s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.5s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  36.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  23.2s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=saga; total time=  26.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=saga; total time=  52.7s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear; total time=   4.0s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear; total time=   3.9s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=sag; total time=  35.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.7s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  39.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  23.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=liblinear; total time=   2.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=saga; total time=  22.8s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.2s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.9s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  37.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  24.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=liblinear; total time=   2.7s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=sag; total time=  33.0s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=saga; total time= 1.4min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=saga; total time=  24.6s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=saga; total time= 1.9min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=saga; total time= 1.6min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=saga; total time=  23.8s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=saga; total time=  56.8s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.8min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.3min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 3.6min\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.3min\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 3.6min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.3min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.3min\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  47.5s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   1.9s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   1.9s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   2.0s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 2.3min\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 4.4min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.3min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.4min\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  50.4s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   1.9s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 2.3min\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.3min\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg; total time= 1.0min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=saga; total time=  26.1s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.5s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  34.6s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  24.2s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=saga; total time=  24.0s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=saga; total time=  48.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  24.1s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=saga; total time=  27.8s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  38.2s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  24.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=saga; total time=  25.9s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=sag; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  40.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  25.7s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=sag; total time=  32.1s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=saga; total time= 1.2min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=liblinear; total time=   2.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=sag; total time=  41.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  38.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  23.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear; total time=   3.0s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear; total time=   2.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=sag; total time=  37.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  42.9s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  22.0s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=liblinear; total time=   2.7s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=sag; total time=  34.2s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=saga; total time= 1.5min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=saga; total time=  23.8s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.2s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=saga; total time= 1.1min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.9min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.3min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.3min\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  58.0s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   2.3s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   2.2s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 2.1min\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 3.2min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.4min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 4.0min\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.4min\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.6s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.7s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.8s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.5s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.5s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.5s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.5s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.7s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.7s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.5min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  49.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   1.9s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   1.8s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   1.7s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 2.1min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 5.1min\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.4min\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time= 1.3min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   1.9s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 2.0min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.4min\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  58.8s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 2.1min\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 3.8min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.4min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.7s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.4min\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  48.7s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 1.8min\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.4min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.6min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  48.8s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 2.0min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 6.8min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  36.1s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear; total time=   5.2s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear; total time=   3.7s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=sag; total time=  40.2s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=saga; total time= 1.0min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=sag; total time=  34.5s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  39.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  25.0s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=saga; total time=  25.5s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  36.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  25.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=saga; total time=  27.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=sag; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=saga; total time= 1.3min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=saga; total time=  22.7s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.2s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=saga; total time= 1.4min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=saga; total time=  25.9s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.7s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  41.1s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  25.8s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=saga; total time=  24.6s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=saga; total time= 1.5min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=saga; total time=  25.9s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.6s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  40.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  21.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=liblinear; total time=   2.8s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=liblinear; total time=   2.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=sag; total time=  37.2s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=saga; total time=  56.0s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.7min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.3min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 4.2min\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.3min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.5min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  46.8s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 1.8min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 4.4min\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.3min\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.7s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.5min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  49.1s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   1.7s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 2.1min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 5.3min\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 3.2min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time= 1.3min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   1.7s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 1.8min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 4.1min\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.2min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.3min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  47.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   1.9s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 2.4min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.7s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.5min\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  48.5s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 2.2min\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 4.0min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.3min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 5.9min\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 3.3min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  59.6s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=saga; total time=  23.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  39.9s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=liblinear; total time=   3.5s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=liblinear; total time=   3.7s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=liblinear; total time=   3.5s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=sag; total time=  31.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=saga; total time=  57.1s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=sag; total time=  38.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=saga; total time=  59.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear; total time=   3.7s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=sag; total time=  38.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.2s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  38.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  20.8s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=liblinear; total time=   3.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=liblinear; total time=   2.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=sag; total time=  28.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=saga; total time= 1.4min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=saga; total time=  25.0s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  39.8s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  22.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear; total time=   2.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=sag; total time=  34.8s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=newton-cg; total time=  39.8s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  23.2s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=liblinear; total time=   2.6s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l2, solver=sag; total time=  32.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=200, multi_class=ovr, penalty=l1, solver=saga; total time= 1.5min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l2, solver=saga; total time=  24.7s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=liblinear; total time=   2.2s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=300, multi_class=ovr, penalty=l1, solver=saga; total time=  57.2s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.7min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.3min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 3.7min\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.3min\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.4min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  49.1s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 2.2min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.4min\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  48.0s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 2.0min\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.3s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 5.1min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.3min\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.6min\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  43.0s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 2.0min\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.6s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.6s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 3.7min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time= 1.2min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   1.9s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 1.9min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.5s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.4min\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  57.2s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 2.0min\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.6s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.6s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 3.6min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.4min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.7s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.6min\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  45.5s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 2.0min\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 4.3min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.4min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.2s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.2s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.6min\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  48.9s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 2.1min\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.3min\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 3.1min\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters: \", search.best_params_)\n",
    "print(\"Best Score: \", search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   34.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:0\n",
      "confusion_mat: [[777 266 107  71  57]\n",
      " [253 494 305 119  55]\n",
      " [ 72 214 394 205  94]\n",
      " [ 34  92 253 473 267]\n",
      " [ 26  83 123 304 700]]\n",
      "macro_f1 0.48232107423081194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   36.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:1\n",
      "confusion_mat: [[820 300 119  55  49]\n",
      " [239 481 294  99  52]\n",
      " [ 71 269 418 214  82]\n",
      " [ 40  94 223 498 237]\n",
      " [ 28  54 105 323 674]]\n",
      "macro_f1 0.49173805437451923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   34.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:2\n",
      "confusion_mat: [[817 253 113  53  45]\n",
      " [253 494 281  88  59]\n",
      " [ 67 243 425 201  70]\n",
      " [ 34  98 273 470 273]\n",
      " [ 32  70 124 327 675]]\n",
      "macro_f1 0.48986483892394955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   35.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:3\n",
      "confusion_mat: [[768 312  96  63  53]\n",
      " [266 464 308  92  56]\n",
      " [ 81 263 406 216  78]\n",
      " [ 40  97 224 447 239]\n",
      " [ 30  62 121 333 723]]\n",
      "macro_f1 0.47667474939236587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:4\n",
      "confusion_mat: [[841 301  95  56  31]\n",
      " [227 476 293 103  56]\n",
      " [ 73 280 416 199  67]\n",
      " [ 41 120 232 453 270]\n",
      " [ 27  79 114 307 680]]\n",
      "macro_f1 0.48674201849117704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   1 out of   1 | elapsed:   36.4s finished\n"
     ]
    }
   ],
   "source": [
    "multicalss_clsfication(features_mc,\n",
    "                       labels_mc,\n",
    "                       LogisticRegression(max_iter=100,\n",
    "                                          class_weight=None,\n",
    "                                          C=0.75,\n",
    "                                          verbose=2,\n",
    "                                          multi_class=\"multinomial\",\n",
    "                                          solver=\"newton-cg\",\n",
    "                                          penalty=\"l2\",\n",
    "                                          n_jobs=10),\n",
    "                       \"test_submission_part_5_LR.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.30886509\n",
      "Iteration 2, loss = 0.99568896\n",
      "Iteration 3, loss = 0.80236244\n",
      "Iteration 4, loss = 0.53189787\n",
      "Iteration 5, loss = 0.25581912\n",
      "Iteration 6, loss = 0.12250000\n",
      "Iteration 7, loss = 0.07927090\n",
      "Iteration 8, loss = 0.06234768\n",
      "Iteration 9, loss = 0.05343931\n",
      "Iteration 10, loss = 0.04881382\n",
      "Iteration 11, loss = 0.04616399\n",
      "Iteration 12, loss = 0.04423752\n",
      "Iteration 13, loss = 0.04168202\n",
      "Iteration 14, loss = 0.04057117\n",
      "Iteration 15, loss = 0.03942698\n",
      "Iteration 16, loss = 0.03841142\n",
      "Iteration 17, loss = 0.03924785\n",
      "Iteration 18, loss = 0.03841147\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time= 1.2min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   2.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   1.8s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 1.5min\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.7s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.6s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   1.5s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.6s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=sag; total time=   1.3s\n",
      "[CV] END C=0.75, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 4.3min\n",
      "[CV] END C=0.75, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.2min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.4min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  47.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 2.0min\n",
      "[CV] END C=1, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 4.1min\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.4min\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.6s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.4s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.5s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.5s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.5s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.5s\n",
      "[CV] END C=1, class_weight=None, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.6s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.6min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  47.5s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 2.4min\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   1.4s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   1.3s\n",
      "[CV] END C=1.25, class_weight=balanced, max_iter=100, multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   1.5s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=newton-cg; total time= 1.5min\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  51.7s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=sag; total time= 2.2min\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l2, solver=saga; total time= 1.3min\n",
      "[CV] END C=1.25, class_weight=None, max_iter=100, multi_class=multinomial, penalty=l1, solver=saga; total time= 3.7min\n",
      "Iteration 19, loss = 0.03675158\n",
      "Iteration 20, loss = 0.03648507\n",
      "Iteration 21, loss = 0.03657999\n",
      "Iteration 22, loss = 0.03676680\n",
      "Iteration 23, loss = 0.03548330\n",
      "Iteration 24, loss = 0.03583492\n",
      "Iteration 25, loss = 0.03548519\n",
      "Iteration 26, loss = 0.03555843\n",
      "Iteration 27, loss = 0.03500550\n",
      "Iteration 28, loss = 0.03493377\n",
      "Iteration 29, loss = 0.03428767\n",
      "Iteration 30, loss = 0.03393001\n",
      "Iteration 31, loss = 0.03394332\n",
      "Iteration 32, loss = 0.03406534\n",
      "Iteration 33, loss = 0.03346983\n",
      "Iteration 34, loss = 0.03500311\n",
      "Iteration 35, loss = 0.06735772\n",
      "Iteration 36, loss = 0.08014166\n",
      "Iteration 37, loss = 0.04825466\n",
      "Iteration 38, loss = 0.03572744\n",
      "Iteration 39, loss = 0.03434316\n",
      "Iteration 40, loss = 0.03362048\n",
      "Iteration 41, loss = 0.03370011\n",
      "Iteration 42, loss = 0.03313686\n",
      "Iteration 43, loss = 0.03321449\n",
      "Iteration 44, loss = 0.03297098\n",
      "Iteration 45, loss = 0.03262317\n",
      "Iteration 46, loss = 0.03337441\n",
      "Iteration 47, loss = 0.03292960\n",
      "Iteration 48, loss = 0.03197093\n",
      "Iteration 49, loss = 0.03269967\n",
      "Iteration 50, loss = 0.03214333\n",
      "Iteration 51, loss = 0.03242315\n",
      "Iteration 52, loss = 0.03175921\n",
      "Iteration 53, loss = 0.03189173\n",
      "Iteration 54, loss = 0.03197969\n",
      "Iteration 55, loss = 0.03189143\n",
      "Iteration 56, loss = 0.03249242\n",
      "Iteration 57, loss = 0.03219109\n",
      "Iteration 58, loss = 0.03195404\n",
      "Iteration 59, loss = 0.03204938\n",
      "Iteration 60, loss = 0.03174098\n",
      "Iteration 61, loss = 0.03097934\n",
      "Iteration 62, loss = 0.03180063\n",
      "Iteration 63, loss = 0.03089022\n",
      "Iteration 64, loss = 0.03143218\n",
      "Iteration 65, loss = 0.03084782\n",
      "Iteration 66, loss = 0.03100282\n",
      "Iteration 67, loss = 0.03114718\n",
      "Iteration 68, loss = 0.03095148\n",
      "Iteration 69, loss = 0.03110224\n",
      "Iteration 70, loss = 0.03089918\n",
      "Iteration 71, loss = 0.03094690\n",
      "Iteration 72, loss = 0.03081464\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "fold:0\n",
      "confusion_mat: [[724 252 115  55  40]\n",
      " [262 455 268  95  68]\n",
      " [ 97 277 357 194  84]\n",
      " [ 61 168 320 462 329]\n",
      " [ 50 102 116 287 600]]\n",
      "macro_f1 0.44420931986637663\n",
      "Iteration 1, loss = 1.30400197\n",
      "Iteration 2, loss = 0.99061046\n",
      "Iteration 3, loss = 0.79801862\n",
      "Iteration 4, loss = 0.53560766\n",
      "Iteration 5, loss = 0.26900020\n",
      "Iteration 6, loss = 0.12991421\n",
      "Iteration 7, loss = 0.08211895\n",
      "Iteration 8, loss = 0.06284283\n",
      "Iteration 9, loss = 0.05462265\n",
      "Iteration 10, loss = 0.04921693\n",
      "Iteration 11, loss = 0.04578984\n",
      "Iteration 12, loss = 0.04353187\n",
      "Iteration 13, loss = 0.04219046\n",
      "Iteration 14, loss = 0.04016601\n",
      "Iteration 15, loss = 0.04038739\n",
      "Iteration 16, loss = 0.03975835\n",
      "Iteration 17, loss = 0.03817595\n",
      "Iteration 18, loss = 0.03784864\n",
      "Iteration 19, loss = 0.03757894\n",
      "Iteration 20, loss = 0.03682143\n",
      "Iteration 21, loss = 0.03602357\n",
      "Iteration 22, loss = 0.03534884\n",
      "Iteration 23, loss = 0.03601614\n",
      "Iteration 24, loss = 0.03604380\n",
      "Iteration 25, loss = 0.03534863\n",
      "Iteration 26, loss = 0.03496739\n",
      "Iteration 27, loss = 0.03414991\n",
      "Iteration 28, loss = 0.03394169\n",
      "Iteration 29, loss = 0.03343763\n",
      "Iteration 30, loss = 0.03406146\n",
      "Iteration 31, loss = 0.03408870\n",
      "Iteration 32, loss = 0.03358267\n",
      "Iteration 33, loss = 0.03313479\n",
      "Iteration 34, loss = 0.03362742\n",
      "Iteration 35, loss = 0.03315835\n",
      "Iteration 36, loss = 0.03312021\n",
      "Iteration 37, loss = 0.03302063\n",
      "Iteration 38, loss = 0.03301269\n",
      "Iteration 39, loss = 0.03317255\n",
      "Iteration 40, loss = 0.03336293\n",
      "Iteration 41, loss = 0.03258103\n",
      "Iteration 42, loss = 0.03228299\n",
      "Iteration 43, loss = 0.03190648\n",
      "Iteration 44, loss = 0.03187856\n",
      "Iteration 45, loss = 0.03247359\n",
      "Iteration 46, loss = 0.03183353\n",
      "Iteration 47, loss = 0.03226764\n",
      "Iteration 48, loss = 0.12118060\n",
      "Iteration 49, loss = 0.07680249\n",
      "Iteration 50, loss = 0.03824169\n",
      "Iteration 51, loss = 0.03328406\n",
      "Iteration 52, loss = 0.03226712\n",
      "Iteration 53, loss = 0.03226418\n",
      "Iteration 54, loss = 0.03219655\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "fold:1\n",
      "confusion_mat: [[732 339 121  85  62]\n",
      " [253 402 270 127  64]\n",
      " [119 262 377 199 111]\n",
      " [ 45 120 237 427 275]\n",
      " [ 41 102 123 335 610]]\n",
      "macro_f1 0.4327332400631251\n",
      "Iteration 1, loss = 1.30713391\n",
      "Iteration 2, loss = 0.99207028\n",
      "Iteration 3, loss = 0.79382409\n",
      "Iteration 4, loss = 0.52774527\n",
      "Iteration 5, loss = 0.26204773\n",
      "Iteration 6, loss = 0.12645407\n",
      "Iteration 7, loss = 0.07845850\n",
      "Iteration 8, loss = 0.06247117\n",
      "Iteration 9, loss = 0.05331873\n",
      "Iteration 10, loss = 0.04832947\n",
      "Iteration 11, loss = 0.04489734\n",
      "Iteration 12, loss = 0.04186977\n",
      "Iteration 13, loss = 0.04075566\n",
      "Iteration 14, loss = 0.03884177\n",
      "Iteration 15, loss = 0.03904717\n",
      "Iteration 16, loss = 0.03727410\n",
      "Iteration 17, loss = 0.03656090\n",
      "Iteration 18, loss = 0.03634472\n",
      "Iteration 19, loss = 0.03567320\n",
      "Iteration 20, loss = 0.03507955\n",
      "Iteration 21, loss = 0.03473439\n",
      "Iteration 22, loss = 0.03440649\n",
      "Iteration 23, loss = 0.03428540\n",
      "Iteration 24, loss = 0.03423705\n",
      "Iteration 25, loss = 0.03435349\n",
      "Iteration 26, loss = 0.03313861\n",
      "Iteration 27, loss = 0.03297238\n",
      "Iteration 28, loss = 0.03308254\n",
      "Iteration 29, loss = 0.03402475\n",
      "Iteration 30, loss = 0.03315062\n",
      "Iteration 31, loss = 0.03274010\n",
      "Iteration 32, loss = 0.03254863\n",
      "Iteration 33, loss = 0.03149773\n",
      "Iteration 34, loss = 0.03201073\n",
      "Iteration 35, loss = 0.03173986\n",
      "Iteration 36, loss = 0.03678206\n",
      "Iteration 37, loss = 0.04779178\n",
      "Iteration 38, loss = 0.07310411\n",
      "Iteration 39, loss = 0.05208828\n",
      "Iteration 40, loss = 0.03607674\n",
      "Iteration 41, loss = 0.03301193\n",
      "Iteration 42, loss = 0.03179531\n",
      "Iteration 43, loss = 0.03184339\n",
      "Iteration 44, loss = 0.03193249\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "fold:2\n",
      "confusion_mat: [[675 235 109  61  50]\n",
      " [314 462 314 151  87]\n",
      " [123 281 444 290 129]\n",
      " [ 41 115 208 391 287]\n",
      " [ 41  54 121 293 562]]\n",
      "macro_f1 0.4359865718390428\n",
      "Iteration 1, loss = 1.30581753\n",
      "Iteration 2, loss = 0.98757484\n",
      "Iteration 3, loss = 0.79225568\n",
      "Iteration 4, loss = 0.52626338\n",
      "Iteration 5, loss = 0.25560559\n",
      "Iteration 6, loss = 0.12323756\n",
      "Iteration 7, loss = 0.07982969\n",
      "Iteration 8, loss = 0.06362421\n",
      "Iteration 9, loss = 0.05481509\n",
      "Iteration 10, loss = 0.05002493\n",
      "Iteration 11, loss = 0.04642471\n",
      "Iteration 12, loss = 0.04385116\n",
      "Iteration 13, loss = 0.04315745\n",
      "Iteration 14, loss = 0.04118123\n",
      "Iteration 15, loss = 0.04104587\n",
      "Iteration 16, loss = 0.03943616\n",
      "Iteration 17, loss = 0.03823783\n",
      "Iteration 18, loss = 0.03800712\n",
      "Iteration 19, loss = 0.03735277\n",
      "Iteration 20, loss = 0.03862063\n",
      "Iteration 21, loss = 0.03678329\n",
      "Iteration 22, loss = 0.03665002\n",
      "Iteration 23, loss = 0.03581095\n",
      "Iteration 24, loss = 0.03634382\n",
      "Iteration 25, loss = 0.03592075\n",
      "Iteration 26, loss = 0.03561088\n",
      "Iteration 27, loss = 0.03515755\n",
      "Iteration 28, loss = 0.03465104\n",
      "Iteration 29, loss = 0.03472030\n",
      "Iteration 30, loss = 0.03417466\n",
      "Iteration 31, loss = 0.03459178\n",
      "Iteration 32, loss = 0.03498311\n",
      "Iteration 33, loss = 0.03444212\n",
      "Iteration 34, loss = 0.03392199\n",
      "Iteration 35, loss = 0.03363350\n",
      "Iteration 36, loss = 0.03401916\n",
      "Iteration 37, loss = 0.03355294\n",
      "Iteration 38, loss = 0.03298102\n",
      "Iteration 39, loss = 0.03401096\n",
      "Iteration 40, loss = 0.03339309\n",
      "Iteration 41, loss = 0.03318473\n",
      "Iteration 42, loss = 0.03296144\n",
      "Iteration 43, loss = 0.03252825\n",
      "Iteration 44, loss = 0.03307774\n",
      "Iteration 45, loss = 0.03228332\n",
      "Iteration 46, loss = 0.03279410\n",
      "Iteration 47, loss = 0.03251332\n",
      "Iteration 48, loss = 0.03241415\n",
      "Iteration 49, loss = 0.04325400\n",
      "Iteration 50, loss = 0.12822499\n",
      "Iteration 51, loss = 0.05540795\n",
      "Iteration 52, loss = 0.03619341\n",
      "Iteration 53, loss = 0.03356812\n",
      "Iteration 54, loss = 0.03290484\n",
      "Iteration 55, loss = 0.03238669\n",
      "Iteration 56, loss = 0.03224021\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "fold:3\n",
      "confusion_mat: [[726 309 150  91  63]\n",
      " [280 407 270 121  73]\n",
      " [110 257 405 255 126]\n",
      " [ 32 107 207 365 253]\n",
      " [ 31  75 148 346 631]]\n",
      "macro_f1 0.4297114202097637\n",
      "Iteration 1, loss = 1.30677588\n",
      "Iteration 2, loss = 0.98733999\n",
      "Iteration 3, loss = 0.79100213\n",
      "Iteration 4, loss = 0.52435779\n",
      "Iteration 5, loss = 0.25970441\n",
      "Iteration 6, loss = 0.12538781\n",
      "Iteration 7, loss = 0.07983868\n",
      "Iteration 8, loss = 0.06341543\n",
      "Iteration 9, loss = 0.05477992\n",
      "Iteration 10, loss = 0.04978261\n",
      "Iteration 11, loss = 0.04649864\n",
      "Iteration 12, loss = 0.04396839\n",
      "Iteration 13, loss = 0.04360385\n",
      "Iteration 14, loss = 0.04186929\n",
      "Iteration 15, loss = 0.04061372\n",
      "Iteration 16, loss = 0.03995592\n",
      "Iteration 17, loss = 0.03929433\n",
      "Iteration 18, loss = 0.03927320\n",
      "Iteration 19, loss = 0.03843720\n",
      "Iteration 20, loss = 0.03758226\n",
      "Iteration 21, loss = 0.03731091\n",
      "Iteration 22, loss = 0.03645193\n",
      "Iteration 23, loss = 0.03666968\n",
      "Iteration 24, loss = 0.03632713\n",
      "Iteration 25, loss = 0.03586415\n",
      "Iteration 26, loss = 0.03575885\n",
      "Iteration 27, loss = 0.03554003\n",
      "Iteration 28, loss = 0.03634372\n",
      "Iteration 29, loss = 0.03493557\n",
      "Iteration 30, loss = 0.03538768\n",
      "Iteration 31, loss = 0.03543981\n",
      "Iteration 32, loss = 0.03460898\n",
      "Iteration 33, loss = 0.03622527\n",
      "Iteration 34, loss = 0.06543600\n",
      "Iteration 35, loss = 0.06581959\n",
      "Iteration 36, loss = 0.04685047\n",
      "Iteration 37, loss = 0.03691160\n",
      "Iteration 38, loss = 0.03556791\n",
      "Iteration 39, loss = 0.03454332\n",
      "Iteration 40, loss = 0.03482938\n",
      "Iteration 41, loss = 0.03496051\n",
      "Iteration 42, loss = 0.03412802\n",
      "Iteration 43, loss = 0.03415776\n",
      "Iteration 44, loss = 0.03400986\n",
      "Iteration 45, loss = 0.03382867\n",
      "Iteration 46, loss = 0.03294982\n",
      "Iteration 47, loss = 0.03360304\n",
      "Iteration 48, loss = 0.03321249\n",
      "Iteration 49, loss = 0.03273179\n",
      "Iteration 50, loss = 0.03351880\n",
      "Iteration 51, loss = 0.03309321\n",
      "Iteration 52, loss = 0.03297658\n",
      "Iteration 53, loss = 0.03331526\n",
      "Iteration 54, loss = 0.03298712\n",
      "Iteration 55, loss = 0.03258428\n",
      "Iteration 56, loss = 0.03244428\n",
      "Iteration 57, loss = 0.03243811\n",
      "Iteration 58, loss = 0.03302770\n",
      "Iteration 59, loss = 0.03234999\n",
      "Iteration 60, loss = 0.03263898\n",
      "Iteration 61, loss = 0.03262643\n",
      "Iteration 62, loss = 0.03212948\n",
      "Iteration 63, loss = 0.03240749\n",
      "Iteration 64, loss = 0.03242531\n",
      "Iteration 65, loss = 0.03204981\n",
      "Iteration 66, loss = 0.03176891\n",
      "Iteration 67, loss = 0.03253370\n",
      "Iteration 68, loss = 0.03195484\n",
      "Iteration 69, loss = 0.03154250\n",
      "Iteration 70, loss = 0.03225600\n",
      "Iteration 71, loss = 0.03161737\n",
      "Iteration 72, loss = 0.03192408\n",
      "Iteration 73, loss = 0.03138204\n",
      "Iteration 74, loss = 0.03106573\n",
      "Iteration 75, loss = 0.03153925\n",
      "Iteration 76, loss = 0.03117528\n",
      "Iteration 77, loss = 0.03168240\n",
      "Iteration 78, loss = 0.03172940\n",
      "Iteration 79, loss = 0.03117478\n",
      "Iteration 80, loss = 0.03105829\n",
      "Iteration 81, loss = 0.03050362\n",
      "Iteration 82, loss = 0.03264640\n",
      "Iteration 83, loss = 0.05853390\n",
      "Iteration 84, loss = 0.06532673\n",
      "Iteration 85, loss = 0.03897255\n",
      "Iteration 86, loss = 0.03221822\n",
      "Iteration 87, loss = 0.03177493\n",
      "Iteration 88, loss = 0.03176619\n",
      "Iteration 89, loss = 0.03182390\n",
      "Iteration 90, loss = 0.03138497\n",
      "Iteration 91, loss = 0.03148628\n",
      "Iteration 92, loss = 0.03119289\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "fold:4\n",
      "confusion_mat: [[726 297 136  56  65]\n",
      " [255 394 288 121  56]\n",
      " [116 292 417 251  98]\n",
      " [ 44  83 156 298 216]\n",
      " [ 59 112 185 413 703]]\n",
      "macro_f1 0.4259653558818851\n"
     ]
    }
   ],
   "source": [
    "multicalss_clsfication(features_mc,\n",
    "                       labels_mc,\n",
    "                       MLPClassifier(hidden_layer_sizes=(512,256),\n",
    "                                                        max_iter=500, \n",
    "                                                        alpha=0.0001,\n",
    "                                                        solver='adam',\n",
    "                                                        random_state=0,\n",
    "                                                        tol=0.0001,verbose=True),\n",
    "                       \"test_submission_part_5_MLP.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>style</th>\n",
       "      <th>category</th>\n",
       "      <th>alltext</th>\n",
       "      <th>allreview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>all of the reviews for this product are fake.</td>\n",
       "      <td>all fake reviews, beware.</td>\n",
       "      <td>{'size:': ' polaris h4'}</td>\n",
       "      <td>0</td>\n",
       "      <td>all fake reviews, beware. all of the reviews f...</td>\n",
       "      <td>all fake reviews, beware. all of the reviews f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>wrong part. our fault.</td>\n",
       "      <td>one star</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>one star wrong part. our fault. nan</td>\n",
       "      <td>one star wrong part. our fault.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>this wire set it really sucks!!!</td>\n",
       "      <td>one star</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>one star this wire set it really sucks!!! nan</td>\n",
       "      <td>one star this wire set it really sucks!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>first use, it leaked instantly. even at 5 buck...</td>\n",
       "      <td>one star</td>\n",
       "      <td>{'color:': ' clear', 'style:': ' 45 degree'}</td>\n",
       "      <td>0</td>\n",
       "      <td>one star first use, it leaked instantly. even ...</td>\n",
       "      <td>one star first use, it leaked instantly. even ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>didn't fit</td>\n",
       "      <td>one star</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>one star didn't fit nan</td>\n",
       "      <td>one star didn't fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29184</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>this is the same plush toy that the official d...</td>\n",
       "      <td>well constructed, very soft</td>\n",
       "      <td>nan</td>\n",
       "      <td>5</td>\n",
       "      <td>well constructed, very soft this is the same p...</td>\n",
       "      <td>well constructed, very soft this is the same p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29185</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>my grandson loved this. it is a great toy, he ...</td>\n",
       "      <td>fun toy</td>\n",
       "      <td>nan</td>\n",
       "      <td>5</td>\n",
       "      <td>fun toy my grandson loved this. it is a great ...</td>\n",
       "      <td>fun toy my grandson loved this. it is a great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29186</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>my kiddo loves them! we are a rock climbing fa...</td>\n",
       "      <td>and now the play set has a nice climbing feature</td>\n",
       "      <td>nan</td>\n",
       "      <td>5</td>\n",
       "      <td>and now the play set has a nice climbing featu...</td>\n",
       "      <td>and now the play set has a nice climbing featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29187</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>i bought this for my niece (age 2) and mailed ...</td>\n",
       "      <td>my brother said she liked it and i haven't see...</td>\n",
       "      <td>{'style:': ' standard version'}</td>\n",
       "      <td>5</td>\n",
       "      <td>my brother said she liked it and i haven't see...</td>\n",
       "      <td>my brother said she liked it and i haven't see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29188</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>my daughter will love this! she's a huge ninja...</td>\n",
       "      <td>ninja fan will love!</td>\n",
       "      <td>nan</td>\n",
       "      <td>5</td>\n",
       "      <td>ninja fan will love! my daughter will love thi...</td>\n",
       "      <td>ninja fan will love! my daughter will love thi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29189 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       overall  verified                                         reviewText  \\\n",
       "0            1     False      all of the reviews for this product are fake.   \n",
       "1            1      True                             wrong part. our fault.   \n",
       "2            1      True                   this wire set it really sucks!!!   \n",
       "3            1      True  first use, it leaked instantly. even at 5 buck...   \n",
       "4            1      True                                         didn't fit   \n",
       "...        ...       ...                                                ...   \n",
       "29184        5      True  this is the same plush toy that the official d...   \n",
       "29185        5      True  my grandson loved this. it is a great toy, he ...   \n",
       "29186        5      True  my kiddo loves them! we are a rock climbing fa...   \n",
       "29187        5      True  i bought this for my niece (age 2) and mailed ...   \n",
       "29188        5      True  my daughter will love this! she's a huge ninja...   \n",
       "\n",
       "                                                 summary  \\\n",
       "0                              all fake reviews, beware.   \n",
       "1                                               one star   \n",
       "2                                               one star   \n",
       "3                                               one star   \n",
       "4                                               one star   \n",
       "...                                                  ...   \n",
       "29184                        well constructed, very soft   \n",
       "29185                                            fun toy   \n",
       "29186   and now the play set has a nice climbing feature   \n",
       "29187  my brother said she liked it and i haven't see...   \n",
       "29188                               ninja fan will love!   \n",
       "\n",
       "                                              style  category  \\\n",
       "0                          {'size:': ' polaris h4'}         0   \n",
       "1                                               nan         0   \n",
       "2                                               nan         0   \n",
       "3      {'color:': ' clear', 'style:': ' 45 degree'}         0   \n",
       "4                                               nan         0   \n",
       "...                                             ...       ...   \n",
       "29184                                           nan         5   \n",
       "29185                                           nan         5   \n",
       "29186                                           nan         5   \n",
       "29187               {'style:': ' standard version'}         5   \n",
       "29188                                           nan         5   \n",
       "\n",
       "                                                 alltext  \\\n",
       "0      all fake reviews, beware. all of the reviews f...   \n",
       "1                    one star wrong part. our fault. nan   \n",
       "2          one star this wire set it really sucks!!! nan   \n",
       "3      one star first use, it leaked instantly. even ...   \n",
       "4                                one star didn't fit nan   \n",
       "...                                                  ...   \n",
       "29184  well constructed, very soft this is the same p...   \n",
       "29185  fun toy my grandson loved this. it is a great ...   \n",
       "29186  and now the play set has a nice climbing featu...   \n",
       "29187  my brother said she liked it and i haven't see...   \n",
       "29188  ninja fan will love! my daughter will love thi...   \n",
       "\n",
       "                                               allreview  \n",
       "0      all fake reviews, beware. all of the reviews f...  \n",
       "1                        one star wrong part. our fault.  \n",
       "2              one star this wire set it really sucks!!!  \n",
       "3      one star first use, it leaked instantly. even ...  \n",
       "4                                    one star didn't fit  \n",
       "...                                                  ...  \n",
       "29184  well constructed, very soft this is the same p...  \n",
       "29185  fun toy my grandson loved this. it is a great ...  \n",
       "29186  and now the play set has a nice climbing featu...  \n",
       "29187  my brother said she liked it and i haven't see...  \n",
       "29188  ninja fan will love! my daughter will love thi...  \n",
       "\n",
       "[29189 rows x 8 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data handling\n",
    "def transfer(x):\n",
    "    class_map = {\"automotive\":0,\"CDs\":1,\"grocery\":2,\"cell_phones\":3,\"sports\":4,\"toys\":5,}\n",
    "    if x in class_map.keys():\n",
    "        return class_map[x]\n",
    "    else:\n",
    "        return x\n",
    "train[\"category\"]=train[\"category\"].apply(transfer)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_mat_kmeans(X,y_true,y_pred):\n",
    "    silhouette_avg = silhouette_score(X, y_pred)\n",
    "    rand_index = adjusted_rand_score(y_true, y_pred)\n",
    "    print(\"silhouette_score:\",silhouette_avg)\n",
    "    print(\"rand_index:\",rand_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_kmeans = CountVectorizer(stop_words=\"english\")\n",
    "transformer_kmeans =TfidfTransformer()\n",
    "features_kmeans= vectorizer.fit_transform(train[\"alltext\"].values)\n",
    "features_kmeans = transformer.fit_transform(features_kmeans)\n",
    "features_kmeans = features_kmeans.toarray()\n",
    "test_features_kmeans= vectorizer.transform(test[\"alltext\"].values)\n",
    "test_features_kmeans = transformer.fit_transform(test_features_kmeans)\n",
    "test_features_kmeans=test_features_kmeans.toarray()\n",
    "\n",
    "labels_kmeans = train[\"category\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = KMeans(6,init=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(X,y,model:KMeans,test_file_name:str):\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    for idx,(train_index, test_index) in enumerate(kf.split(X)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(\"fold:{}\".format(idx))\n",
    "        eval_mat_kmeans(X_test,y_test,y_pred)\n",
    "    test_predicted = model.predict(test_features_kmeans)\n",
    "    test_submission = pd.DataFrame({'id':np.arange(len(test_predicted)), 'predicted':test_predicted})\n",
    "    test_submission.to_csv(test_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kmeans(features_kmeans,labels_kmeans,cls,\"test_submission_part_6.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e9c9ba383ed874a743ae53bb821ceb135a4fa7230ae5f709929b53f9450f0c65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
